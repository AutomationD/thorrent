# -*- coding: utf-8 -*-from __future__ import unicode_literals__author__ = 'dmitry'import osimport bencodeimport urllibimport loggingimport stringfrom pprint import pprintfrom bs4 import BeautifulSoupTEST_TORRENT_FILE = "[kinozal.tv]id1184343.torrent"INPUT_DIR = '/Users/dmitry/dev/thorrent/thorrent/test/samples/src'OUTPUT_DIR = '/Users/dmitry/dev/thorrent/thorrent/test/samples/out'TORRENT_DIR = '/Users/dmitry/dev/thorrent/thorrent/test/samples/torrents'torrent_file_name = TEST_TORRENT_FILElogging.basicConfig(format='%(asctime)s %(message)s', filename='thorrent.log', level=logging.DEBUG)def get_torrent_file_contents(torrent_file_name):    torrent_file_path = os.path.join(TORRENT_DIR, torrent_file_name)    if not os.path.exists(torrent_file_path):        print('Skipped, .torrent is not found: "%s' % torrent_file_path)        return None    else:        try:            torrent_file_data = bencode.bdecode(open(torrent_file_path, 'rb').read())            return torrent_file_data        except:            print("Error, can't extract tracker url from .torrent file %s" % torrent_file_path)            return Nonedef torrent_html_content_is_valid(soup):    return soup.body.find('a', attrs={'class': 'r0'})def get_torrent_html_codepage():    returndef get_torrent_html(torrent_data):    tracker_url = torrent_data['comment']    print ("URL: '%s'" % tracker_url)    try:        response = urllib.urlopen(tracker_url)        html_page = response.read()    except:        print("Error, Can't load tracker page '%s'" % tracker_url)        return None    html_page = html_page.decode('cp1251')    return html_pagehtml = get_torrent_html(get_torrent_file_contents(torrent_file_name))#torrent_file_data = get_torrent_file(torrent_file_name)soup = BeautifulSoup(html)if not torrent_html_content_is_valid(soup):    logging.error("Html content is not valid for " + torrent_file_name)else:    logging.debug("Html content is valid for " + torrent_file_name)    ## kinozal.tv    desc = soup.h2.find_all('b')    #print desc    for d in desc:        param_name = d.text.strip()        param_value = d.next_sibling.strip()        if "Название" in param_name:            title = param_value        if "Оригинальное название" in param_name:            original_title = param_value        if "Год выпуска" in param_name:            year = param_valueprint title + " " + original_title + " " +year